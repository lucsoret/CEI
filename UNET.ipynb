{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.ndimage\n",
    "from skimage.segmentation import clear_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skimage, os\n",
    "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "from skimage.measure import label,regionprops, perimeter\n",
    "from skimage.morphology import binary_dilation, binary_opening\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage import measure, feature\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import data\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import dicom\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonypamart/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution3D, Convolution2D, MaxPooling3D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This funciton reads a '.mhd' file using SimpleITK and return the image array, \n",
    "origin and spacing of the image.\n",
    "'''\n",
    "def load_itk(filename):\n",
    "    # Reads the image using SimpleITK\n",
    "    itkimage = sitk.ReadImage(filename)\n",
    "    \n",
    "    # Convert the image to a  numpy array first and then shuffle the dimensions to get axis in the order z,y,x\n",
    "    ct_scan = sitk.GetArrayFromImage(itkimage)\n",
    "    \n",
    "    # Read the origin of the ct_scan, will be used to convert the coordinates from world to voxel and vice versa.\n",
    "    origin = np.array(list(reversed(itkimage.GetOrigin())))\n",
    "    \n",
    "    # Read the spacing along each dimension\n",
    "    spacing = np.array(list(reversed(itkimage.GetSpacing())))\n",
    "    \n",
    "    return ct_scan, origin, spacing\n",
    "\n",
    "'''\n",
    "This function is used to convert the world coordinates to voxel coordinates using \n",
    "the origin and spacing of the ct_scan\n",
    "'''\n",
    "def world_2_voxel(world_coordinates, origin, spacing):\n",
    "    stretched_voxel_coordinates = np.absolute(world_coordinates - origin)\n",
    "    voxel_coordinates = stretched_voxel_coordinates / spacing\n",
    "    return voxel_coordinates\n",
    "\n",
    "'''\n",
    "This function is used to convert the voxel coordinates to world coordinates using \n",
    "the origin and spacing of the ct_scan.\n",
    "'''\n",
    "def voxel_2_world(voxel_coordinates, origin, spacing):\n",
    "    stretched_voxel_coordinates = voxel_coordinates * spacing\n",
    "    world_coordinates = stretched_voxel_coordinates + origin\n",
    "    return world_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq(start, stop, step=1):\n",
    "    n = int(round((stop - start)/float(step)))\n",
    "    if n > 1:\n",
    "        return([start + step*i for i in range(n+1)])\n",
    "    else:\n",
    "        return([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function is used to create spherical regions in binary masks\n",
    "at the given locations and radius.\n",
    "'''\n",
    "def draw_circles(image,cands,origin,spacing):\n",
    "    #make empty matrix, which will be filled with the mask\n",
    "    RESIZE_SPACING = [1, 1, 1]\n",
    "    image_mask = np.zeros(image.shape)\n",
    "\n",
    "    #run over all the nodules in the lungs\n",
    "    for ca in cands.values:\n",
    "        #get middel x-,y-, and z-worldcoordinate of the nodule\n",
    "        radius = np.ceil(ca[4])/2\n",
    "        coord_x = ca[1]\n",
    "        coord_y = ca[2]\n",
    "        coord_z = ca[3]\n",
    "        image_coord = np.array((coord_z,coord_y,coord_x))\n",
    "\n",
    "        #determine voxel coordinate given the worldcoordinate\n",
    "        image_coord = world_2_voxel(image_coord,origin,spacing)\n",
    "\n",
    "        #determine the range of the nodule\n",
    "        noduleRange = seq(-radius, radius, RESIZE_SPACING[0])\n",
    "\n",
    "        #create the mask\n",
    "        for x in noduleRange:\n",
    "            for y in noduleRange:\n",
    "                for z in noduleRange:\n",
    "                    coords = world_2_voxel(np.array((coord_z+z,coord_y+y,coord_x+x)),origin,spacing)\n",
    "                    if (np.linalg.norm(image_coord-coords) * RESIZE_SPACING[0]) < radius:\n",
    "                        image_mask[int(coords[0]),int(coords[1]),int(coords[2])] = int(1)\n",
    "\n",
    "    return image_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segment_lung_from_ct_scan(ct_scan):\n",
    "    return np.asarray([get_segmented_lungs(slice) for slice in ct_scan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_segmented_lungs(im, plot=False):\n",
    "    \n",
    "    '''\n",
    "    This funtion segments the lungs from the given 2D slice.\n",
    "    '''\n",
    "    if plot == True:\n",
    "        f, plots = plt.subplots(8, 1, figsize=(5, 40))\n",
    "    '''\n",
    "    Step 1: Convert into a binary image. \n",
    "    '''\n",
    "    binary = im < 604\n",
    "    if plot == True:\n",
    "        plots[0].axis('off')\n",
    "        plots[0].imshow(binary, cmap=plt.cm.bone) \n",
    "    '''\n",
    "    Step 2: Remove the blobs connected to the border of the image.\n",
    "    '''\n",
    "    cleared = clear_border(binary)\n",
    "    if plot == True:\n",
    "        plots[1].axis('off')\n",
    "        plots[1].imshow(cleared, cmap=plt.cm.bone) \n",
    "    '''\n",
    "    Step 3: Label the image.\n",
    "    '''\n",
    "    label_image = label(cleared)\n",
    "    if plot == True:\n",
    "        plots[2].axis('off')\n",
    "        plots[2].imshow(label_image, cmap=plt.cm.bone) \n",
    "    '''\n",
    "    Step 4: Keep the labels with 2 largest areas.\n",
    "    '''\n",
    "    areas = [r.area for r in regionprops(label_image)]\n",
    "    areas.sort()\n",
    "    if len(areas) > 2:\n",
    "        for region in regionprops(label_image):\n",
    "            if region.area < areas[-2]:\n",
    "                for coordinates in region.coords:                \n",
    "                       label_image[coordinates[0], coordinates[1]] = 0\n",
    "    binary = label_image > 0\n",
    "    if plot == True:\n",
    "        plots[3].axis('off')\n",
    "        plots[3].imshow(binary, cmap=plt.cm.bone) \n",
    "    '''\n",
    "    Step 5: Erosion operation with a disk of radius 2. This operation is \n",
    "    seperate the lung nodules attached to the blood vessels.\n",
    "    '''\n",
    "    selem = disk(2)\n",
    "    binary = binary_erosion(binary, selem)\n",
    "    if plot == True:\n",
    "        plots[4].axis('off')\n",
    "        plots[4].imshow(binary, cmap=plt.cm.bone) \n",
    "    '''\n",
    "    Step 6: Closure operation with a disk of radius 10. This operation is \n",
    "    to keep nodules attached to the lung wall.\n",
    "    '''\n",
    "    selem = disk(10)\n",
    "    binary = binary_closing(binary, selem)\n",
    "    if plot == True:\n",
    "        plots[5].axis('off')\n",
    "        plots[5].imshow(binary, cmap=plt.cm.bone) \n",
    "    '''\n",
    "    Step 7: Fill in the small holes inside the binary mask of lungs.\n",
    "    '''\n",
    "    edges = roberts(binary)\n",
    "    binary = ndi.binary_fill_holes(edges)\n",
    "    if plot == True:\n",
    "        plots[6].axis('off')\n",
    "        plots[6].imshow(binary, cmap=plt.cm.bone) \n",
    "    '''\n",
    "    Step 8: Superimpose the binary mask on the input image.\n",
    "    '''\n",
    "    get_high_vals = binary == 0\n",
    "    im[get_high_vals] = 0\n",
    "    if plot == True:\n",
    "        plots[7].axis('off')\n",
    "        plots[7].imshow(im, cmap=plt.cm.bone) \n",
    "        \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes the path to a '.mhd' file as input and \n",
    "is used to create the nodule masks and segmented lungs after \n",
    "rescaling to 1mm size in all directions. It saved them in the .npz\n",
    "format. It also takes the list of nodule locations in that CT Scan as \n",
    "input.\n",
    "'''\n",
    "def create_nodule_mask(imagePath, cands, imageName):\n",
    "    #if os.path.isfile(imagePath.replace('original',SAVE_FOLDER_image)) == False:\n",
    "    img, origin, spacing = load_itk(imagePath)\n",
    "\n",
    "    #calculate resize factor\n",
    "    RESIZE_SPACING = [1, 1, 1]\n",
    "    resize_factor = spacing / RESIZE_SPACING\n",
    "    new_real_shape = img.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize = new_shape / img.shape\n",
    "    new_spacing = spacing / real_resize\n",
    "    \n",
    "    #resize image\n",
    "    lung_img = scipy.ndimage.interpolation.zoom(img, real_resize)\n",
    "    \n",
    "    # Segment the lung structure\n",
    "    lung_img = lung_img + 1024\n",
    "    lung_mask = segment_lung_from_ct_scan(lung_img)\n",
    "    lung_img = lung_img - 1024\n",
    "\n",
    "    #create nodule mask\n",
    "    nodule_mask = draw_circles(lung_img,cands,origin,new_spacing)\n",
    "\n",
    "    lung_img_512, lung_mask_512, nodule_mask_512 = np.zeros((lung_img.shape[0], 512, 512)), np.zeros((lung_mask.shape[0], 512, 512)), np.zeros((nodule_mask.shape[0], 512, 512))\n",
    "\n",
    "    original_shape = lung_img.shape\t\n",
    "    for z in range(lung_img.shape[0]):\n",
    "        offset = (512 - original_shape[1])\n",
    "        upper_offset = np.round(offset/2)\n",
    "        lower_offset = offset - upper_offset\n",
    "\n",
    "        new_origin = voxel_2_world([-upper_offset,-lower_offset,0],origin,new_spacing)\n",
    "\n",
    "        lung_img_512[z, upper_offset:-lower_offset,upper_offset:-lower_offset] = lung_img[z,:,:]\n",
    "        lung_mask_512[z, upper_offset:-lower_offset,upper_offset:-lower_offset] = lung_mask[z,:,:]\n",
    "        nodule_mask_512[z, upper_offset:-lower_offset,upper_offset:-lower_offset] = nodule_mask[z,:,:]\n",
    "    \n",
    "    path = '/Users/anthonypamart/Documents/SIR/Projets/CEI/Taff 15 mars/Images/' \n",
    "    # save images.    \n",
    "    np.save(path + imageName + '_lung_img.npz', lung_img_512)\n",
    "    np.save(path + imageName + '_lung_mask.npz', lung_mask_512)\n",
    "    np.save(path + imageName + '_nodule_mask.npz', nodule_mask_512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/anthonypamart/Documents/SIR/Projets/CEI/Taff 15 mars/subset0'\n",
    "images = os.listdir(path)\n",
    "\n",
    "##On ne garde que les images en .mhd\n",
    "images_mhd = [] \n",
    "for i in range(0,len(image)):\n",
    "    if image[i][-4:] == '.mhd':\n",
    "        images_mhd.append(images[i])\n",
    "        \n",
    "##Liste des path de toutes les images\n",
    "images_path = []\n",
    "for i in range(0, len(images_mhd)):\n",
    "    images_path.append(os.path.join(path, images_mhd[i]))\n",
    "\n",
    "first_image_path = images_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "##annotations.csv contient l'id, x, y, z et le diametre des nodules malades\n",
    "cands = pd.read_csv('/Users/anthonypamart/Documents/SIR/Projets/CEI/Taff 15 mars/CSVFILES/annotations.csv')\n",
    "\n",
    "##labels.csv contient l'id, x, y, z et si le nodules est malade ou non\n",
    "labels = pd.read_csv('/Users/anthonypamart/Documents/SIR/Projets/CEI/Taff 15 mars/CSVFILES/candidates.csv')\n",
    "\n",
    "##Liste des cands pour chaque image\n",
    "cands_list = []\n",
    "for i in range(0,len(images_mhd)):\n",
    "    cands_list.append(cands[cands['seriesuid'] == images_mhd[i][0:-4]])\n",
    "\n",
    "first_cands = cands_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "551065"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_img, origin, spacing = load_itk(first_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask = draw_circles(first_img, first_cands, origin, spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = \n",
    "train_label =\n",
    "valid_X = \n",
    "valid_label ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.8 s, sys: 4.59 s, total: 49.4 s\n",
      "Wall time: 51.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_nodule_mask(first_image_path, first_cands, images_mhd[0][0:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change the loss function\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The UNET model is compiled in this function.\n",
    "'''\n",
    "def unet_model():\n",
    "    #inputs = Input((1, 512, 512))\n",
    "    inputs = Input((366,512,512))\n",
    "    \n",
    "    conv1 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(inputs)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(pool1)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(pool3)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Convolution2D(1024, 3, 3, activation='relu', border_mode='same')(pool4)\n",
    "    conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Convolution2D(1024, 3, 3, activation='relu', border_mode='same')(conv5)\n",
    "\n",
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=1)\n",
    "    conv6 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(up6)\n",
    "    conv6 = Dropout(0.2)(conv6)\n",
    "    conv6 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(conv6)\n",
    "\n",
    "    up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=1)\n",
    "    conv7 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(up7)\n",
    "    conv7 = Dropout(0.2)(conv7)\n",
    "    conv7 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv7)\n",
    "\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=1)\n",
    "    conv8 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(up8)\n",
    "    conv8 = Dropout(0.2)(conv8)\n",
    "    conv8 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv8)\n",
    "\n",
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=1)\n",
    "    conv9 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(up9)\n",
    "    conv9 = Dropout(0.2)(conv9)\n",
    "    conv9 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv9)\n",
    "\n",
    "    conv10 = Convolution2D(1, 1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "epochs = 10\n",
    "train_X = \n",
    "train_label =\n",
    "valid_X = \n",
    "valid_label =\n",
    "\n",
    "\n",
    "#inputs = Input((1, 512, 512))\n",
    "inputs = Input((366,512,512))\n",
    "\n",
    "conv1 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(inputs)\n",
    "conv1 = Dropout(0.2)(conv1)\n",
    "conv1 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(pool1)\n",
    "conv2 = Dropout(0.2)(conv2)\n",
    "conv2 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(pool2)\n",
    "conv3 = Dropout(0.2)(conv3)\n",
    "conv3 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(pool3)\n",
    "conv4 = Dropout(0.2)(conv4)\n",
    "conv4 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = Convolution2D(1024, 3, 3, activation='relu', border_mode='same')(pool4)\n",
    "conv5 = Dropout(0.2)(conv5)\n",
    "conv5 = Convolution2D(1024, 3, 3, activation='relu', border_mode='same')(conv5)\n",
    "\n",
    "up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=1)\n",
    "conv6 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(up6)\n",
    "conv6 = Dropout(0.2)(conv6)\n",
    "conv6 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(conv6)\n",
    "\n",
    "up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=1)\n",
    "conv7 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(up7)\n",
    "conv7 = Dropout(0.2)(conv7)\n",
    "conv7 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv7)\n",
    "\n",
    "up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=1)\n",
    "conv8 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(up8)\n",
    "conv8 = Dropout(0.2)(conv8)\n",
    "conv8 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv8)\n",
    "\n",
    "up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=1)\n",
    "conv9 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(up9)\n",
    "conv9 = Dropout(0.2)(conv9)\n",
    "conv9 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv9)\n",
    "\n",
    "conv10 = Convolution2D(1, 1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "model = Model(input=inputs, output=conv10)\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "model = model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Input = np.load('/Users/anthonypamart/Documents/SIR/Projets/CEI/Taff 15 mars/Images/1.3.6.1.4.1.14519.5.2.1.6279.6001.430109407146633213496148200410_lung_img.npz.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-4452dee607b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-222-5ddb5ea3c95a>\u001b[0m in \u001b[0;36munet_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#inputs = Input((1, 512, 512))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m366\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "unet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
